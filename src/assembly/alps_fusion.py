#!/usr/bin/env python3
"""
ALPS Fusion Assembly Script

This script performs ALPS (Assembly of Ligand-Protein Spectra) fusion assembly on processed
de novo sequencing results. It requires summary CSV files generated by denovo_process.py
as input and runs the ALPS.jar tool to assemble peptide sequences.

Pipeline Position:
    1. denovo_process.py → Generate summary CSV files
    2. [THIS SCRIPT] ALPS assembly using summary files → Assembly results
    3. Metric scripts analyze assembly results

Dependencies:
    - ALPS.jar executable (download separately)
    - Summary CSV files from denovo_process.py
    - MGF spectral files
    - Tool confidence threshold CSV file

Supported Tools:
    CasanovoV1, CasanovoV2, PepNet, pNovo3, pi-HelixNovo, pi-PrimeNovo, 
    AdaNovo, ContraNovo, DeepNovo, InstaNovo, PointNovo, PGPointNovo, SMSNet

Usage:
    python alps_fusion.py --tool CasanovoV1 --input_path /path/to/summary --output_path /path/to/assembly --mgf_path /path/to/mgf --confidence_threshold_file /path/to/thresholds.csv
"""

import os
import argparse
import pandas as pd
import numpy as np
import subprocess
import statistics
import yaml
import json
from typing import Dict, Optional, Any


class ConfigLoader:
    """Configuration loader for ALPS Fusion parameters."""
    
    def __init__(self, config_path: Optional[str] = None):
        """
        Initialize configuration loader.
        
        Args:
            config_path: Path to configuration file. If None, uses default path.
        """
        if config_path is None:
            # Default config path is in the src/config directory
            script_dir = os.path.dirname(os.path.abspath(__file__))
            # Go up one level from assembly to src, then into config
            src_dir = os.path.dirname(script_dir)
            config_path = os.path.join(src_dir, 'config', 'alps_fusion.yaml')
        
        self.config_path = config_path
        self.config = self._load_config()
        
        # Get project root directory for resolving relative paths
        self.project_root = self._get_project_root()
    
    def _load_config(self) -> Dict[str, Any]:
        """Load configuration from YAML file."""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            print(f"Loaded configuration from {self.config_path}")
            return config
        except FileNotFoundError:
            print(f"Warning: Configuration file {self.config_path} not found. Using fallback defaults.")
            return self._get_fallback_config()
        except yaml.YAMLError as e:
            print(f"Error parsing YAML config: {e}. Using fallback defaults.")
            return self._get_fallback_config()
    
    def _get_project_root(self) -> str:
        """Get project root directory."""
        # Start from script directory and go up to find project root
        script_dir = os.path.dirname(os.path.abspath(__file__))
        # Go up two levels: assembly -> src -> project_root
        project_root = os.path.dirname(os.path.dirname(script_dir))
        return project_root
    
    def _resolve_path(self, relative_path: str) -> str:
        """Resolve relative path to absolute path based on project root."""
        if os.path.isabs(relative_path):
            return relative_path
        return os.path.join(self.project_root, relative_path)

    def _get_fallback_config(self) -> Dict[str, Any]:
        """Get fallback configuration if config file is not available."""
        return {
            'tool_names': [
                'CasanovoV1', 'CasanovoV2', 'PepNet', 'pNovo3', 'pi-HelixNovo', 
                'pi-PrimeNovo', 'AdaNovo', 'ContraNovo', 'DeepNovo', 'InstaNovo',
                'PointNovo', 'PGPointNovo', 'SMSNet'
            ],
            'default_names': {
                '50ugmAb1': 'mAb1',
                '100ugmAb2': 'mAb2',
                '200ugmAb3': 'mAb3',
                '20230210-mAb4': 'mAb4',
                '20230707-mAb5': 'mAb5',
                '20231203-mAb6': 'mAb6',
                '20231221-mAb7': 'mAb7',
                '20250415-mAb8': 'mAb8'
            },
            'default_parameters': {
                'quality_cutoff': 50,
                'kmer': 7,
                'contigs_alps': 20
            },
            'default_paths': {
                'alps_jar_path': 'ALPS.jar',
                'confidence_threshold_file': 'data/Tool_Confidence_Threshold.csv'
            },
            'base_paths': {
                'denovo_results_base': 'denovo',
                'mgf_files_base': 'monoclonal_antibody',
                'output_base': 'ALPS_Assembly'
            },
            'default_confidence_thresholds': {tool: 50 for tool in [
                'CasanovoV1', 'CasanovoV2', 'PepNet', 'pNovo3', 'pi-HelixNovo', 
                'pi-PrimeNovo', 'AdaNovo', 'ContraNovo', 'DeepNovo', 'InstaNovo',
                'PointNovo', 'PGPointNovo', 'SMSNet'
            ]}
        }
    
    @property
    def tool_names(self) -> set:
        """Get supported tool names."""
        return set(self.config.get('tool_names', []))
    
    @property
    def default_names(self) -> Dict[str, str]:
        """Get default antibody name mapping."""
        return self.config.get('default_names', {})
    
    @property
    def default_parameters(self) -> Dict[str, Any]:
        """Get default processing parameters."""
        return self.config.get('default_parameters', {})
    
    @property
    def default_paths(self) -> Dict[str, str]:
        """Get default file paths (resolved to absolute paths)."""
        paths = self.config.get('default_paths', {})
        resolved_paths = {}
        for key, path in paths.items():
            resolved_paths[key] = self._resolve_path(path)
        return resolved_paths
    
    @property
    def base_paths(self) -> Dict[str, str]:
        """Get base directory paths (resolved to absolute paths)."""
        paths = self.config.get('base_paths', {})
        resolved_paths = {}
        for key, path in paths.items():
            resolved_paths[key] = self._resolve_path(path)
        return resolved_paths
    
    @property
    def tool_file_patterns(self) -> Dict[str, Dict[str, Any]]:
        """Get tool-specific file patterns."""
        return self.config.get('tool_file_patterns', {})
    
    @property
    def tool_input_dirs(self) -> Dict[str, str]:
        """Get tool-specific input directory mapping."""
        return self.config.get('tool_input_dirs', {})
    
    @property
    def mgf_file_pattern(self) -> str:
        """Get MGF file pattern."""
        return self.config.get('mgf_file_pattern', 'spectrum_{sample_name}_HCD.mgf')
    
    @property
    def mgf_subdir(self) -> str:
        """Get MGF subdirectory."""
        return self.config.get('mgf_subdir', 'process1')
    
    @property
    def default_confidence_thresholds(self) -> Dict[str, int]:
        """Get default confidence thresholds."""
        return self.config.get('default_confidence_thresholds', {})


# Global configuration loader
_config_loader = None

def get_config_loader(config_path: Optional[str] = None) -> ConfigLoader:
    """Get global configuration loader instance."""
    global _config_loader
    if _config_loader is None or config_path is not None:
        _config_loader = ConfigLoader(config_path)
    return _config_loader


class ALPSFusion:
    """ALPS Fusion assembly processor for various de novo sequencing tools."""
    
    def __init__(self, confidence_threshold_file: Optional[str] = None, alps_jar_path: Optional[str] = None, 
                 config_path: Optional[str] = None):
        """
        Initialize the ALPS Fusion processor.
        
        Args:
            confidence_threshold_file: Path to the CSV file containing confidence thresholds
            alps_jar_path: Path to the ALPS.jar file
            config_path: Path to configuration file
        """
        # Load configuration
        self.config = get_config_loader(config_path)
        
        # Set paths from config or arguments
        default_paths = self.config.default_paths
        self.alps_jar_path = alps_jar_path or default_paths.get('alps_jar_path', 'ALPS.jar')
        
        # Set default parameters from config
        default_params = self.config.default_parameters
        self.quality_cutoff = default_params.get('quality_cutoff', 50)
        self.kmer = default_params.get('kmer', 7)
        self.contigs_alps = default_params.get('contigs_alps', 20)
        
        # Load confidence thresholds
        confidence_file = confidence_threshold_file or default_paths.get('confidence_threshold_file')
        if confidence_file and os.path.exists(confidence_file):
            df = pd.read_csv(confidence_file)
            self.score_all = pd.Series(df.Confidence_Threshold.values, index=df.Tool).to_dict()
        else:
            # Use default thresholds from config
            self.score_all = self.config.default_confidence_thresholds
    
    def process_casanovo_v1(self, casanovo_path: str, mgf_file: str, resultdir: str) -> None:
        """Process CasanovoV1 results for ALPS assembly."""
        tool = 'CasanovoV1'
        quality_cutoff_local = self.score_all.get(tool, 50)
        
        # Extract titles from MGF file
        titles = self._extract_mgf_titles(mgf_file)
        
        casanovo_out = os.path.join(resultdir, f'{tool}_confScoreThreshold_{self.quality_cutoff}_localScore_{quality_cutoff_local}.csv')
        
        # Find header line
        casanovo_header = self._find_header_line(casanovo_path, "PSH")
        
        # Load and process data
        df_deno = pd.read_csv(casanovo_path, sep="\t", header=casanovo_header)
        df_denovo = df_deno[df_deno['sequence'].notna()].copy()
        df_denovo['PSM_ID'] = df_denovo['PSM_ID'].astype(int)
        df_denovo['PSM_ID'] = df_denovo['PSM_ID'].apply(lambda x: titles[x] if x < len(titles) else None)

        # Process sequences and scores
        sequence = df_denovo['sequence'].tolist()
        PSM_ID = df_denovo['PSM_ID'].tolist()
        Score = [int((i * 100 + 100)/2) for i in df_denovo['search_engine_score[1]'].tolist()]
        
        # Process amino acid scores
        aascore = df_denovo['opt_ms_run[1]_aa_scores'].tolist()
        aascore = [i.replace(',', ' ') for i in aascore]
        aascore = [i.split() for i in aascore]
        aascore = [[str(int(float(j) * 100)) for j in i] for i in aascore]
        aascore = [" ".join(i) for i in aascore]

        # Create output DataFrame
        df_output = self._create_output_dataframe(PSM_ID, sequence, aascore, Score, tool)
        df_filtered = df_output[df_output[f'{tool} Score'] >= quality_cutoff_local]
        
        # Save and run ALPS
        df_filtered.to_csv(casanovo_out, index=False)
        self._run_alps_assembly(casanovo_out, resultdir)

    def process_casanovo_v2(self, casanovo_path: str, mgf_file: str, resultdir: str) -> None:
        """Process CasanovoV2 results for ALPS assembly."""
        tool = 'CasanovoV2'
        quality_cutoff_local = self.score_all.get(tool, 50)
        
        # Extract titles from MGF file
        titles = self._extract_mgf_titles(mgf_file)
        
        casanovo_out = os.path.join(resultdir, f'{tool}_confScoreThreshold_{self.quality_cutoff}_localScore_{quality_cutoff_local}.csv')
        
        # Find header line
        casanovo_header = self._find_header_line(casanovo_path, "PSH")
        
        # Load and process data
        df_deno = pd.read_csv(casanovo_path, sep="\t", header=casanovo_header)
        df_denovo = df_deno[df_deno['sequence'].notna()].copy()
        
        df_denovo['PSM_ID'] = [int(item.replace('ms_run[1]:index=', '')) for item in df_denovo['spectra_ref']]
        df_denovo['PSM_ID'] = df_denovo['PSM_ID'].apply(lambda x: titles[x] if x < len(titles) else None)

        # Process sequences and scores
        sequence = df_denovo['sequence'].tolist()
        PSM_ID = df_denovo['PSM_ID'].tolist()
        Score = [int((i * 100 + 100)/2) for i in df_denovo['search_engine_score[1]'].tolist()]
        
        # Process amino acid scores
        aascore = df_denovo['opt_ms_run[1]_aa_scores'].tolist()
        aascore = [i.replace(',', ' ') for i in aascore]
        aascore = [i.split() for i in aascore]
        aascore = [[str(int(float(j) * 100)) for j in i] for i in aascore]
        aascore = [" ".join(i) for i in aascore]

        # Create output DataFrame
        df_output = self._create_output_dataframe(PSM_ID, sequence, aascore, Score, tool)
        df_filtered = df_output[df_output[f'{tool} Score'] >= quality_cutoff_local]
        
        # Save and run ALPS
        df_filtered.to_csv(casanovo_out, index=False)
        self._run_alps_assembly(casanovo_out, resultdir)

    def process_pepnet(self, pepnet_path: str, resultdir: str) -> None:
        """Process PepNet results for ALPS assembly."""
        tool = 'PepNet'
        quality_cutoff_local = self.score_all.get(tool, 50)
        
        pepnet_out = os.path.join(resultdir, f'{tool}_confScoreThreshold_{self.quality_cutoff}_localScore_{quality_cutoff_local}.csv')
        
        # Load and process data
        pepnet_df = pd.read_csv(pepnet_path, sep='\t')
        pepnet_title = pepnet_df['TITLE'].tolist()
        pepnet_df['Spectrum Name'] = pepnet_title
        
        # Process peptides
        pepnet_peptide = pepnet_df['DENOVO'].tolist()
        pepnet_df['PepNet Peptide'] = [peptide.replace("m", "M(+15.99)").replace("q", "Q(+.98)")
                                      .replace("n", "N(+.98)").replace("C", "C(+57.02)") for peptide in pepnet_peptide]
        
        # Process scores
        pepnet_score = [int(i*100) for i in pepnet_df['Score'].tolist()]
        pepnet_df['PepNet Score'] = pepnet_score
        
        # Process amino acid scores
        aascore = pepnet_df['Positional Score'].tolist()
        aascore = [i.replace('[', '').replace(']', '').replace(',', ' ') for i in aascore]
        aascore = [i.split() for i in aascore]
        aascore = [[str(int(float(j)*100)) for j in i] for i in aascore]
        pepnet_df['PepNet aaScore'] = [" ".join(i) for i in aascore]
        
        # Create output DataFrame
        pepnet_df['Area'] = 1
        pepnet_df = pepnet_df[['Spectrum Name', 'PepNet Peptide', 'PepNet aaScore', 'PepNet Score', 'Area']]
        pepnet_df['PepNet Score'] = pepnet_df['PepNet Score'].astype(int)
        pepnet_df = pepnet_df[pepnet_df['PepNet Score'] >= quality_cutoff_local]
        
        # Save and run ALPS
        pepnet_df.to_csv(pepnet_out, index=False)
        self._run_alps_assembly(pepnet_out, resultdir)

    def process_pnovo3(self, pnovo_path: str, resultdir: str) -> None:
        """Process pNovo3 results for ALPS assembly."""
        tool = 'pNovo3'
        quality_cutoff_local = self.score_all.get(tool, 50)
        
        pnovo_out = os.path.join(resultdir, f'{tool}_confScoreThreshold_{self.quality_cutoff}_localScore_{quality_cutoff_local}.csv')
        
        # Load and process data
        df = pd.read_csv(pnovo_path, sep="\t", header=None)
        df = df[[0, 1, 4, 5]]
        df.columns = ['Spectrum Name', 'pNovo3 Peptide', 'pNovo3 Score', 'pNovo3 aaScore']

        # Filter valid peptides
        peps = list(df['pNovo3 Peptide'])
        aas = list(df['pNovo3 aaScore'])
        loc = [len(str(p)) == len(str(a).split(',')) for p, a in zip(peps, aas)]
        pnovo_df = df[loc].copy()

        # Process peptides
        pnovo_peptide = pnovo_df['pNovo3 Peptide'].tolist()
        pnovo_peptide = [str(i).replace('I','L').replace('a', 'N(+.98)').replace('b', 'Q(+.98)')
                        .replace('B', 'Q(+.98)').replace('c', 'M(+15.99)').replace('C','C(+57.02)') 
                        for i in pnovo_peptide]
        pnovo_df['pNovo3 Peptide'] = pnovo_peptide
        
        # Process scores
        pnovo_score = [int(i) for i in pnovo_df['pNovo3 Score'].tolist()]
        pnovo_df['pNovo3 Score'] = pnovo_score
        
        # Process amino acid scores
        aascore = pnovo_df['pNovo3 aaScore'].tolist()
        aascore = [str(i).replace(',', ' ') for i in aascore]
        aascore = [i.split() for i in aascore]
        aascore = [[str(int(float(j))) for j in i] for i in aascore]
        pnovo_df['pNovo3 aaScore'] = [" ".join(i) for i in aascore]
        
        # Create output DataFrame
        pnovo_df = pnovo_df[['Spectrum Name', 'pNovo3 Peptide', 'pNovo3 aaScore', 'pNovo3 Score']]
        pnovo_df['pNovo3 Score'] = pnovo_df['pNovo3 Score'].astype(int)
        pnovo_df = pnovo_df[pnovo_df['pNovo3 Score'] >= quality_cutoff_local]
        pnovo_df['Area'] = 1
        
        # Save and run ALPS
        pnovo_df.to_csv(pnovo_out, index=False)
        self._run_alps_assembly(pnovo_out, resultdir)

    def process_pi_helixnovo(self, pinovo_path: str, resultdir: str) -> None:
        """Process pi-HelixNovo results for ALPS assembly."""
        tool = 'pi-HelixNovo'
        quality_cutoff_local = self.score_all.get(tool, 50)
        
        pinovo_out = os.path.join(resultdir, f'{tool}_confScoreThreshold_{self.quality_cutoff}_localScore_{quality_cutoff_local}.csv')
        
        # Load and process data
        pinovo_df = pd.read_csv(pinovo_path, sep="\t", header=None)
        pinovo_df = pinovo_df.dropna()
        pinovo_df.columns = ["Title", "sequence", "Score"]
        
        # Process peptides
        pinovo_peptide = pinovo_df['sequence'].tolist()
        pinovo_df['pi-HelixNovo Peptide'] = [str(i).replace('M(+15.99)', 'm').replace('Q(+.98)', 'q')
                                           .replace('N(+.98)', 'n').replace(' ', '').replace('C(+57.02)', 'C') 
                                           for i in pinovo_peptide]
        
        # Process scores
        pinovo_score = pinovo_df['Score']
        pinovo_df['pi-HelixNovo Score'] = [int(i * 100) for i in pinovo_score]
        pinovo_df['pi-HelixNovo aaScore'] = pinovo_df.apply(
            lambda row: ' '.join([str(row['pi-HelixNovo Score'])] * len(row['pi-HelixNovo Peptide'])), axis=1)
        
        # Restore peptide modifications
        pinovo_df['pi-HelixNovo Peptide'] = pinovo_peptide
        pinovo_df['Spectrum Name'] = pinovo_df['Title']
        pinovo_df['Area'] = 1
        
        # Create output DataFrame
        pinovo_df = pinovo_df[['Spectrum Name', 'pi-HelixNovo Peptide', 'pi-HelixNovo aaScore', 'pi-HelixNovo Score', 'Area']]
        pinovo_df['pi-HelixNovo Score'] = pinovo_df['pi-HelixNovo Score'].astype(int)
        pinovo_df = pinovo_df[pinovo_df['pi-HelixNovo Score'] >= quality_cutoff_local]
        
        # Save and run ALPS
        pinovo_df.to_csv(pinovo_out, index=False)
        self._run_alps_assembly(pinovo_out, resultdir)

    def process_pi_primenovo(self, primenovo_path: str, resultdir: str) -> None:
        """Process pi-PrimeNovo results for ALPS assembly."""
        tool = 'pi-PrimeNovo'
        quality_cutoff_local = self.score_all.get(tool, 50)
        
        primenovo_out = os.path.join(resultdir, f'{tool}_confScoreThreshold_{self.quality_cutoff}_localScore_{quality_cutoff_local}.csv')
        
        # Load and process data
        primenovo_df = pd.read_table(primenovo_path)
        primenovo_peptide = primenovo_df['prediction'].tolist()
        
        # Process peptides (first pass - simplified)
        primenovo_df['pi-PrimeNovo Peptide'] = [str(i).replace('M[+15.995]', 'm').replace('Q[+0.984]', 'q')
                                               .replace('N[+0.984]', 'n').replace(' ', '').replace('C[+57.021]', 'C')
                                               .replace('[-17.027]-Q', 'p').replace('-[17.027]-Q', 'p')
                                               .replace('[+43.006-17.027]-','').replace('+[43.006-17.027]','')
                                               .replace('[17.027]-','').replace('[-17.027]-','').replace('-[17.027]','')
                                               .replace('[+43.006]-','').replace('+[43.006]','')
                                               .replace('[+42.011]-','').replace('+[42.011]','') for i in primenovo_peptide]
        
        # Process scores
        score = primenovo_df['score']
        primenovo_df['pi-PrimeNovo Score'] = [int(i * 100) for i in score]
        primenovo_df['pi-PrimeNovo aaScore'] = primenovo_df.apply(
            lambda row: ' '.join([str(row['pi-PrimeNovo Score'])] * len(row['pi-PrimeNovo Peptide'])), axis=1)
        
        # Process peptides (second pass - with proper modifications)
        primenovo_df['pi-PrimeNovo Peptide'] = [str(i).replace('M[+15.995]', 'M(+15.99)').replace('Q[+0.984]', 'Q(+.98)')
                                               .replace('N[+0.984]', 'N(+.98)').replace(' ', '').replace('C[+57.021]', 'C(+57.02)')
                                               .replace('[-17.027]-Q', 'Q(-17.03)').replace('-[17.027]-Q', 'Q(-17.03)')
                                               .replace('[+43.006-17.027]-','').replace('+[43.006-17.027]','')
                                               .replace('[17.027]-','').replace('[-17.027]-','').replace('-[17.027]','')
                                               .replace('[+43.006]-','').replace('+[43.006]','')
                                               .replace('[+42.011]-','').replace('+[42.011]','') for i in primenovo_peptide]
        
        primenovo_df['Spectrum Name'] = primenovo_df['label']
        primenovo_df['Area'] = 1
        
        # Create output DataFrame
        primenovo_df = primenovo_df[['Spectrum Name', 'pi-PrimeNovo Peptide', 'pi-PrimeNovo aaScore', 'pi-PrimeNovo Score', 'Area']]
        primenovo_df['pi-PrimeNovo Score'] = primenovo_df['pi-PrimeNovo Score'].astype(int)
        primenovo_df = primenovo_df[primenovo_df['pi-PrimeNovo Score'] >= quality_cutoff_local]
        
        # Save and run ALPS
        primenovo_df.to_csv(primenovo_out, index=False)
        self._run_alps_assembly(primenovo_out, resultdir)

    def process_adanovo(self, adanovo_path: str, mgf_file: str, resultdir: str) -> None:
        """Process AdaNovo results for ALPS assembly."""
        tool = 'AdaNovo'
        quality_cutoff_local = self.score_all.get(tool, 50)
        
        # Extract titles from MGF file
        titles = self._extract_mgf_titles(mgf_file)
        
        adanovo_out = os.path.join(resultdir, f'{tool}_confScoreThreshold_{self.quality_cutoff}_localScore_{quality_cutoff_local}.csv')
        
        # Find header line
        adanovo_header = self._find_header_line(adanovo_path, "PSH")
        
        # Load and process data
        df_deno = pd.read_csv(adanovo_path, sep="\t", header=adanovo_header)
        df_denovo = df_deno[df_deno['sequence'].notna()].copy()

        df_denovo['PSM_ID'] = [int(item.replace('ms_run[1]:index=', '')) for item in df_denovo['spectra_ref']]
        df_denovo['PSM_ID'] = df_denovo['PSM_ID'].apply(lambda x: titles[x] if x < len(titles) else None)
        
        # Process sequences and scores
        PSM_ID = df_denovo['PSM_ID'].tolist()
        sequence = df_denovo['sequence'].tolist()
        Score = [int((i * 100 + 100)/2) for i in df_denovo['search_engine_score[1]'].tolist()]
        
        # Process amino acid scores
        aascore = df_denovo['opt_ms_run[1]_aa_scores'].tolist()
        aascore = [i.replace(',', ' ') for i in aascore]
        aascore = [i.split() for i in aascore]
        aascore = [[str(int(float(j) * 100)) for j in i] for i in aascore]
        aascore = [" ".join(i) for i in aascore]

        # Create output DataFrame
        df_output = self._create_output_dataframe(PSM_ID, sequence, aascore, Score, tool)
        df_filtered = df_output[df_output[f'{tool} Score'] >= quality_cutoff_local]
        
        # Save and run ALPS
        df_filtered.to_csv(adanovo_out, index=False)
        self._run_alps_assembly(adanovo_out, resultdir)

    def process_contranovo(self, contranovo_path: str, resultdir: str) -> None:
        """Process ContraNovo results for ALPS assembly."""
        tool = 'ContraNovo'
        quality_cutoff_local = self.score_all.get(tool, 50)
        
        contranovo_out = os.path.join(resultdir, f'{tool}_confScoreThreshold_{self.quality_cutoff}_localScore_{quality_cutoff_local}.csv')
        
        # Find header line
        contranovo_header = self._find_header_line(contranovo_path, "PSH")
        
        # Load and process data
        df_deno = pd.read_csv(contranovo_path, sep="\t", header=contranovo_header)
        df_denovo = df_deno[df_deno['sequence'].notna()].copy()
        
        df_denovo['PSM_ID'] = [i.replace('ms_run[','').replace(']','') for i in df_denovo['spectra_ref']]

        sequence = df_denovo['sequence'].tolist()
        PSM_ID = df_denovo['PSM_ID'].tolist()
        Score = [int((i * 100 + 100)/2) for i in df_denovo['search_engine_score[1]'].tolist()]
        
        # Process amino acid scores
        aascore = df_denovo['opt_ms_run[1]_aa_scores'].tolist()
        aascore = [i.replace(',', ' ') for i in aascore]
        aascore = [i.split() for i in aascore]
        aascore = [[str(int(float(j) * 100)) for j in i] for i in aascore]
        df_denovo['aaScore'] = [" ".join(i) for i in aascore]
        aascore = df_denovo['aaScore'].tolist()

        # Complex sequence processing
        seq = []
        for s, aa in zip(sequence, aascore):
            s_modified = s.replace('M+15.995', 'm') \
                      .replace('Q+0.984', 'q') \
                      .replace('N+0.984', 'n') \
                      .replace('C+57.021', 'C') \
                      .replace('+42.011', 'g') \
                      .replace('+43.006-17.027', 'd') \
                      .replace('-17.027','e') \
                      .replace('+43.006','f')
            
            aa_list = aa.split()
            if len(s_modified) != len(aa_list):
                s_modified = s_modified.replace('d', 'fe')
            seq.append(s_modified)

        # Filter excluded characters
        filtered_sequences = []
        filtered_aascores = []
        excluded_chars = {'p', 'd', 'e', 'f', 'g'}

        for s, aa in zip(seq, aascore):
            aa_list = aa.split()
            if len(s) != len(aa_list):
                raise ValueError(f"序列长度与分数数量不匹配: 序列长度 {len(s)}, 分数数量 {len(aa_list)}")
            
            filtered = [(char, score) for char, score in zip(s, aa_list) if char not in excluded_chars]
            filtered_chars, filtered_scores = zip(*filtered) if filtered else ([], [])
            
            filtered_sequences.append(''.join(filtered_chars))
            filtered_aascores.append(' '.join(filtered_scores))

        filtered_sequences = [seqe.replace('C','C(+57.02)').replace('m','M(+15.99)')
                             .replace('q','Q(+.98)').replace('n','N(+.98)') for seqe in filtered_sequences]
        
        # Create output DataFrame
        df_output = self._create_output_dataframe(PSM_ID, filtered_sequences, filtered_aascores, Score, tool)
        df_filtered = df_output[df_output[f'{tool} Score'] >= quality_cutoff_local]
        
        # Save and run ALPS
        df_filtered.to_csv(contranovo_out, index=False)
        self._run_alps_assembly(contranovo_out, resultdir)

    def process_deepnovo(self, deepnovo_path: str, resultdir: str) -> None:
        """Process DeepNovo results for ALPS assembly."""
        tool = 'DeepNovo'
        quality_cutoff_local = self.score_all.get(tool, 50)
        
        deepnovo_out = os.path.join(resultdir, f'{tool}_confScoreThreshold_{self.quality_cutoff}_localScore_{quality_cutoff_local}.csv')
        
        # Load and process data
        deepno_df = pd.read_csv(deepnovo_path, sep="\t", header=0)
        deepno_df = deepno_df[['scan', 'predicted_score', 'predicted_sequence', 'predicted_position_score']]
        deepnovo_df = deepno_df[deepno_df['predicted_sequence'].notna()].copy()

        # Process peptides
        deepnovo_peptide = deepnovo_df['predicted_sequence'].tolist()
        for i in range(len(deepnovo_peptide)):
            deepnovo_peptide[i] = str(deepnovo_peptide[i])
            deepnovo_peptide[i] = deepnovo_peptide[i].replace(",", "").replace("I", "L").replace("Cmod", "C(+57.02)") \
                                 .replace("Mmod", "M(+15.99)").replace("Nmod", "N(+.98)").replace("Qmod", "Q(+.98)")
        deepnovo_df['predicted_sequence'] = deepnovo_peptide
        deepnovo_df.columns = ['Spectrum Name','DeepNovo Score', 'DeepNovo Peptide', 'DeepNovo aaScore']

        # Process scores
        deepnovo_score = deepnovo_df['DeepNovo Score']
        deepnovo_df['DeepNovo Score'] = [int(np.exp(i) * 100) if not pd.isna(i) else 0 for i in deepnovo_score]

        # Process amino acid scores
        deepnovo_aascore = deepnovo_df['DeepNovo aaScore'].tolist()
        deepnovo_aascore = [str(i).replace(",", " ") for i in deepnovo_aascore]
        deepnovo_aascore = [i.split() for i in deepnovo_aascore]
        deepnovo_aascore = [[str(int(np.exp(float(j)) * 100)) if j not in ['nan', 'NaN', '', None] else '' for j in i] for i in deepnovo_aascore]
        deepnovo_df['DeepNovo aaScore'] = [" ".join(i) for i in deepnovo_aascore]
        
        deepnovo_df['Area'] = 1
        deepnovo_df['DeepNovo Score'] = deepnovo_df['DeepNovo Score'].astype(int)
        deepnovo_df = deepnovo_df[deepnovo_df['DeepNovo Score'] >= quality_cutoff_local]
        deepnovo_df = deepnovo_df[['Spectrum Name', 'DeepNovo Peptide', 'DeepNovo aaScore', 'DeepNovo Score', 'Area']]
        
        # Save and run ALPS
        deepnovo_df.to_csv(deepnovo_out, index=False)
        self._run_alps_assembly(deepnovo_out, resultdir)

    def process_instanovo(self, instanovo_path: str, mgf_file: str, resultdir: str) -> None:
        """Process InstaNovo results for ALPS assembly."""
        tool = 'InstaNovo'
        quality_cutoff_local = self.score_all.get(tool, 50)
        
        instanovo_out = os.path.join(resultdir, f'{tool}_confScoreThreshold_{self.quality_cutoff}_localScore_{quality_cutoff_local}.csv')
        
        # Extract titles from MGF file
        titles = self._extract_mgf_titles(mgf_file)
           
        # Load and process data
        df_deno = pd.read_csv(instanovo_path)
        df_denovo = df_deno[df_deno['predictions'].notna()].copy()

        df_denovo['PSM_ID'] = [int(item) for item in df_denovo['scan_number']]
        df_denovo['PSM_ID'] = df_denovo['PSM_ID'].apply(lambda x: titles[x] if x < len(titles) else None)

        sequence = df_denovo['predictions'].tolist()
        PSM_ID = df_denovo['PSM_ID'].tolist()
        Score = [int(np.exp(i) * 100) for i in df_denovo['log_probabilities'].tolist()]
        
        # Process amino acid scores
        aascore = df_denovo['token_log_probabilities'].tolist()
        aascore = [i.replace(',', ' ').replace('[','').replace(']','') for i in aascore]
        aascore = [i.split() for i in aascore]
        aascore = [[str(int(np.exp(float(i[j])) * 100)) for j in range(0, len(i)-1)] for i in aascore]
        aascore = [" ".join(i) for i in aascore]

        seq = [str(i).replace('M[UNIMOD:35]', 'M(+15.99)').replace('Q[UNIMOD:7]', 'Q(+.98)')
               .replace('N[UNIMOD:7]', 'N(+.98)').replace('C[UNIMOD:4]', 'C(+57.02)').replace('I','L') for i in sequence]
        
        # Create initial DataFrame
        df_output = pd.DataFrame({
            'Spectrum Name': PSM_ID,
            'InstaNovo Peptide': seq,
            'InstaNovo Score': Score,
            'InstaNovo aaScore': aascore
        })
        
        df_output['Area'] = 1
        df_output['InstaNovo Score'] = df_output['InstaNovo Score'].astype(int)
        df_output = df_output[df_output['InstaNovo Score'] >= quality_cutoff_local]
        df_output = df_output[['Spectrum Name', 'InstaNovo Peptide', 'InstaNovo aaScore', 'InstaNovo Score', 'Area']]

        # Filter by length matching
        peps = [i.replace('C(+57.02)','C').replace('M(+15.99)','m').replace('Q(+.98)','q').replace('N(+.98)','n') for i in df_output['InstaNovo Peptide']]
        aas = list(df_output['InstaNovo aaScore'])
        loc = [len(p) == len(a.split()) for p, a in zip(peps, aas)]
        df_filtered = df_output[loc].copy()
        
        # Save and run ALPS
        df_filtered.to_csv(instanovo_out, index=False)
        self._run_alps_assembly(instanovo_out, resultdir)

    def process_pointnovo(self, pointnovo_path: str, mgf_file: str, resultdir: str) -> None:
        """Process PointNovo results for ALPS assembly."""
        tool = 'PointNovo'
        quality_cutoff_local = self.score_all.get(tool, 50)
        
        pointnovo_out = os.path.join(resultdir, f'{tool}_confScoreThreshold_{self.quality_cutoff}_localScore_{quality_cutoff_local}.csv')
        
        # Extract titles from MGF file
        titles = self._extract_mgf_titles(mgf_file)
        
        # Load and process data
        pointno_df = pd.read_csv(pointnovo_path, sep="\t", header=0)
        pointno_df['PSM_ID'] = [int(item) for item in pointno_df['feature_id']]
        pointno_df['PSM_ID'] = pointno_df['PSM_ID'].apply(lambda x: titles[x-1] if x < len(titles) else None)
        
        pointno_df = pointno_df[['PSM_ID', 'predicted_sequence', 'predicted_score', 'predicted_position_score']]
        pointnovo_df = pointno_df[pointno_df['predicted_sequence'].notna()].copy()

        # Process peptides
        pointnovo_peptide = pointnovo_df['predicted_sequence'].tolist()
        for i in range(len(pointnovo_peptide)):
            pointnovo_peptide[i] = str(pointnovo_peptide[i])
            pointnovo_peptide[i] = pointnovo_peptide[i].replace(",", "").replace("I", "L") \
                                  .replace("N(Deamidation)", "N(+.98)").replace("Q(Deamidation)", "Q(+.98)") \
                                  .replace("C(Carbamidomethylation)", "C(+57.02)").replace("M(Oxidation)", "M(+15.99)")
        pointnovo_df['predicted_sequence'] = pointnovo_peptide
        pointnovo_df.columns = ['Spectrum Name','PointNovo Peptide', 'PointNovo Score', 'PointNovo aaScore']

        # Process scores
        pointnovo_score = pointnovo_df['PointNovo Score']
        pointnovo_df['PointNovo Score'] = [int(np.exp(i) * 100) if not pd.isna(i) else 0 for i in pointnovo_score]

        # Process amino acid scores
        pointnovo_aascore = pointnovo_df['PointNovo aaScore'].tolist()
        pointnovo_aascore = [str(i).replace(",", " ") for i in pointnovo_aascore]
        pointnovo_aascore = [i.split() for i in pointnovo_aascore]
        pointnovo_aascore = [[str(int(np.exp(float(j)) * 100)) if j not in ['nan', 'NaN', '', None] else '' for j in i] for i in pointnovo_aascore]
        pointnovo_df['PointNovo aaScore'] = [" ".join(i) for i in pointnovo_aascore]

        pointnovo_df = pointnovo_df[['Spectrum Name','PointNovo Peptide', 'PointNovo aaScore', 'PointNovo Score']]
        pointnovo_df['Area'] = 1

        pointnovo_df['PointNovo Score'] = pointnovo_df['PointNovo Score'].astype(int)
        pointnovo_df = pointnovo_df[pointnovo_df['PointNovo Score'] >= quality_cutoff_local]
        
        # Save and run ALPS
        pointnovo_df.to_csv(pointnovo_out, index=False)
        self._run_alps_assembly(pointnovo_out, resultdir)

    def process_pgpointnovo(self, pgpointnovo_path: str, mgf_file: str, resultdir: str) -> None:
        """Process PGPointNovo results for ALPS assembly."""
        tool = 'PGPointNovo'
        quality_cutoff_local = self.score_all.get(tool, 50)
        
        pgpointnovo_out = os.path.join(resultdir, f'{tool}_confScoreThreshold_{self.quality_cutoff}_localScore_{quality_cutoff_local}.csv')
        
        # Extract titles from MGF file
        titles = self._extract_mgf_titles(mgf_file)
        
        # Load and process data
        pgpointno_df = pd.read_csv(pgpointnovo_path, sep="\t", header=0)

        pgpointno_df['PSM_ID'] = [int(item) for item in pgpointno_df['feature_id']]
        pgpointno_df['Spectrum Name'] = pgpointno_df['PSM_ID'].apply(lambda x: titles[x-1] if x < len(titles) else None)
        
        pgpointno_df = pgpointno_df[['Spectrum Name', 'predicted_sequence', 'predicted_score', 'predicted_position_score']]
        pgpointnovo_df = pgpointno_df[pgpointno_df['predicted_sequence'].notna()].copy()

        # Process peptides
        pgpointnovo_peptide = pgpointnovo_df['predicted_sequence'].tolist()
        for i in range(len(pgpointnovo_peptide)):
            pgpointnovo_peptide[i] = str(pgpointnovo_peptide[i])
            pgpointnovo_peptide[i] = pgpointnovo_peptide[i].replace(",", "").replace("I", "L") \
                                    .replace("N(Deamidation)", "N(+.98)").replace("Q(Deamidation)", "Q(+.98)") \
                                    .replace("C(Carbamidomethylation)", "C(+57.02)").replace("M(Oxidation)", "M(+15.99)")
        pgpointnovo_df['predicted_sequence'] = pgpointnovo_peptide
        pgpointnovo_df.columns = ['Spectrum Name', 'PGPointNovo Peptide', 'PGPointNovo Score', 'PGPointNovo aaScore']

        # Process scores
        pgpointnovo_score = pgpointnovo_df['PGPointNovo Score']
        pgpointnovo_df['PGPointNovo Score'] = [int(np.exp(i) * 100) if not pd.isna(i) else 0 for i in pgpointnovo_score]

        # Process amino acid scores
        pgpointnovo_aascore = pgpointnovo_df['PGPointNovo aaScore'].tolist()
        pgpointnovo_aascore = [str(i).replace(",", " ") for i in pgpointnovo_aascore]
        pgpointnovo_aascore = [i.split() for i in pgpointnovo_aascore]
        pgpointnovo_aascore = [[str(int(np.exp(float(j)) * 100)) if j not in ['nan', 'NaN', '', None] else '' for j in i] for i in pgpointnovo_aascore]

        pgpointnovo_df['PGPointNovo aaScore'] = [" ".join(i) for i in pgpointnovo_aascore]

        pgpointnovo_df = pgpointnovo_df[['Spectrum Name','PGPointNovo Peptide', 'PGPointNovo aaScore', 'PGPointNovo Score']]
        pgpointnovo_df['Area'] = 1

        pgpointnovo_df['PGPointNovo Score'] = pgpointnovo_df['PGPointNovo Score'].astype(int)
        pgpointnovo_df = pgpointnovo_df[pgpointnovo_df['PGPointNovo Score'] >= quality_cutoff_local]
        
        # Save and run ALPS
        pgpointnovo_df.to_csv(pgpointnovo_out, index=False)
        self._run_alps_assembly(pgpointnovo_out, resultdir)

    def process_smsnet(self, smsnet_path: str, mgf_file: str, resultdir: str) -> None:
        """Process SMSNet results for ALPS assembly."""
        tool = 'SMSNet'
        quality_cutoff_local = self.score_all.get(tool, 50)
        
        smsnet_out = os.path.join(resultdir, f'{tool}_confScoreThreshold_{self.quality_cutoff}_localScore_{quality_cutoff_local}.csv')
        
        # Extract titles from MGF file
        titles = self._extract_mgf_titles(mgf_file)
                
        # Load and process data
        with open(smsnet_path) as f, open(smsnet_path + '_prob') as g:
            smsnet_peptide = pd.Series([line.rstrip() for line in f])
            peptide_list = [x.replace(" ", "").replace("I", "L") for x in smsnet_peptide]
            
            smsnet_peptide = pd.DataFrame(peptide_list)
            aa_score = g.readlines()
            aa_score = [i.strip().split(' ') for i in aa_score]
            
            score_sum = []
            for i in range(len(aa_score)):
                if not aa_score[i] == ['']:
                    for j in range(len(aa_score[i])):
                        aa_score[i][j] = int(float(np.exp(float(aa_score[i][j])) * 100))
                else:
                    aa_score[i] = [0]
                    
            for i in range(len(aa_score)):
                if not aa_score[i] == [0]:
                    score_sum.append(int(statistics.mean(aa_score[i])))
                else:
                    score_sum.append(0)
                    
            df = pd.DataFrame({'aaScore': aa_score, 'Peptide Score': score_sum})
            smsnet_df = pd.concat([smsnet_peptide, df], axis=1)
            smsnet_df['Spectrum Name'] = titles
            smsnet_df.columns = ['SMSNet Peptide', 'SMSNet aaScore', 'SMSNet Score','Spectrum Name']
            
            clist = ['Spectrum Name','SMSNet Peptide', 'SMSNet aaScore', 'SMSNet Score']
            smsnet_df = smsnet_df[clist]
            
            smsnet_aascore = smsnet_df['SMSNet aaScore'].tolist()
            smsnet_df['SMSNet aaScore'] = [str(i).replace(' ', '').replace(',', ' ').replace('[', '').replace(']', '') for i in smsnet_aascore]
            smsnet_df['Area'] = 1
            smsnet_df['SMSNet Peptide'] = smsnet_df['SMSNet Peptide'].astype(str)
            smsnet_df['SMSNet Peptide'] = smsnet_df['SMSNet Peptide'].str.strip()
            smsnet_df1 = smsnet_df[smsnet_df['SMSNet Peptide'].str.strip() != ''].copy()
            smsnet_df1 = smsnet_df1[~smsnet_df1['SMSNet Peptide'].str.contains('<unk>|<s>', na=False)]
            smsnet_df1['SMSNet Peptide'] = [i.replace('C','C(+57.02)').replace('m','M(+15.99)')
                                          .replace('n','N(+.98)').replace('q','Q(+.98)') for i in smsnet_df1['SMSNet Peptide']]
            smsnet_df1['SMSNet Score'] = smsnet_df1['SMSNet Score'].astype(int)
            smsnet_df1 = smsnet_df1[smsnet_df1['SMSNet Score'] >= quality_cutoff_local]
            smsnet_df1 = smsnet_df1[smsnet_df1['SMSNet Peptide'].notna()]

            # Save and run ALPS
            smsnet_df1.to_csv(smsnet_out, index=False)
            self._run_alps_assembly(smsnet_out, resultdir)

    def _extract_mgf_titles(self, mgf_file: str) -> list:
        """Extract TITLE lines from MGF file."""
        titles = []
        try:
            with open(mgf_file, 'r') as fr:
                lines = fr.readlines()
                for line in lines:
                    if 'TITLE=' in line:
                        titles.append(line.strip().split('TITLE=')[-1])
        except FileNotFoundError:
            print(f"Warning: MGF file {mgf_file} not found. Using empty titles list.")
        return titles

    def _find_header_line(self, file_path: str, header_marker: str) -> int:
        """Find the line number where the header starts."""
        with open(file_path) as f:
            for i, line in enumerate(f):
                if line.startswith(header_marker):
                    return i
        return 0

    def _create_output_dataframe(self, psm_ids: list, sequences: list, aascores: list, scores: list, tool: str) -> pd.DataFrame:
        """Create standardized output DataFrame."""
        data = np.empty((len(psm_ids), 5), dtype='object')
        data[:, 0] = psm_ids
        data[:, 1] = sequences
        data[:, 2] = aascores
        data[:, 3] = scores
        data[:, 4] = 1

        columns = ['Spectrum Name', f'{tool} Peptide', f'{tool} aaScore', f'{tool} Score', 'Area']
        df = pd.DataFrame(data, columns=columns)
        df[f'{tool} Score'] = df[f'{tool} Score'].astype(int)
        return df

    def _run_alps_assembly(self, csv_file: str, resultdir: str) -> None:
        """Run ALPS assembly using Java jar."""
        try:
            subprocess.run(
                ['java', '-jar', self.alps_jar_path, csv_file, str(self.kmer), str(self.contigs_alps)],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.PIPE,
                cwd=resultdir
            )
        except subprocess.CalledProcessError as e:
            print(f"Warning: ALPS assembly failed for {csv_file}: {e}")
        except FileNotFoundError:
            print(f"Warning: ALPS jar not found at {self.alps_jar_path}")

    def setup_output_directories(self, output_base_path: str, tools: list, mabs: list) -> None:
        """Setup output directory structure."""
        for tool in tools:
            tool_path = os.path.join(output_base_path, tool)
            os.makedirs(tool_path, exist_ok=True)
            for mab in mabs:
                mab_path = os.path.join(tool_path, mab)
                os.makedirs(mab_path, exist_ok=True)

    def process_tool(self, tool: str, input_path: str, output_path: str, mgf_path: Optional[str] = None, 
                    names_mapping: Optional[Dict[str, str]] = None) -> None:
        """
        Process a specific tool for all available samples.
        
        Args:
            tool: Tool name to process
            input_path: Base input path containing tool results
            output_path: Base output path for ALPS assembly
            mgf_path: Base path to MGF files (required for some tools)
            names_mapping: Mapping from directory names to sample names
        """
        if tool not in self.config.tool_names:
            raise ValueError(f"Unknown tool: {tool}. Supported tools: {self.config.tool_names}")
        
        if names_mapping is None:
            names_mapping = self.config.default_names
        
        # Get tool-specific directory and file patterns from config
        tool_input_dirs = self.config.tool_input_dirs
        tool_file_patterns = self.config.tool_file_patterns
        base_paths = self.config.base_paths
        
        tool_input_dir = tool_input_dirs.get(tool, tool.lower().replace('-', ''))
        tool_input_path = os.path.join(input_path, tool_input_dir)
        tool_output_path = os.path.join(output_path, tool)
        
        if not os.path.exists(tool_input_path):
            print(f"Warning: Input path {tool_input_path} does not exist")
            return
            
        mabs = os.listdir(tool_input_path)
        
        for mab in mabs:
            print(f"Processing {tool} for {mab}")
            mab_input_path = os.path.join(tool_input_path, mab)
            mab_output_path = os.path.join(tool_output_path, mab)
            os.makedirs(mab_output_path, exist_ok=True)
            
            try:
                # Get file pattern for this tool
                file_pattern_info = tool_file_patterns.get(tool, {})
                input_file_pattern = file_pattern_info.get('input_file', '')
                input_subdir = file_pattern_info.get('input_subdir', '')
                requires_mgf = file_pattern_info.get('requires_mgf', False)
                
                # Build input file path
                if input_subdir:
                    input_file_base = os.path.join(mab_input_path, input_subdir)
                else:
                    input_file_base = mab_input_path
                
                # Format file pattern with variables
                sample_name = names_mapping.get(mab, mab)
                input_file_name = input_file_pattern.format(mab=mab, sample_name=sample_name)
                input_file = os.path.join(input_file_base, input_file_name)
                
                # Build MGF file path if needed
                mgf_file = None
                if requires_mgf and mgf_path:
                    mgf_pattern = self.config.mgf_file_pattern.format(sample_name=sample_name)
                    mgf_file = os.path.join(mgf_path, mab, self.config.mgf_subdir, mgf_pattern)
                
                # Call appropriate processing method
                if tool == 'CasanovoV1':
                    self.process_casanovo_v1(input_file, mgf_file, mab_output_path)
                elif tool == 'CasanovoV2':
                    self.process_casanovo_v2(input_file, mgf_file, mab_output_path)
                elif tool == 'PepNet':
                    self.process_pepnet(input_file, mab_output_path)
                elif tool == 'pNovo3':
                    self.process_pnovo3(input_file, mab_output_path)
                elif tool == 'pi-HelixNovo':
                    self.process_pi_helixnovo(input_file, mab_output_path)
                elif tool == 'pi-PrimeNovo':
                    self.process_pi_primenovo(input_file, mab_output_path)
                elif tool == 'AdaNovo':
                    self.process_adanovo(input_file, mgf_file, mab_output_path)
                elif tool == 'ContraNovo':
                    self.process_contranovo(input_file, mab_output_path)
                elif tool == 'DeepNovo':
                    self.process_deepnovo(input_file, mab_output_path)
                elif tool == 'InstaNovo':
                    self.process_instanovo(input_file, mgf_file, mab_output_path)
                elif tool == 'PointNovo':
                    self.process_pointnovo(input_file, mgf_file, mab_output_path)
                elif tool == 'PGPointNovo':
                    self.process_pgpointnovo(input_file, mgf_file, mab_output_path)
                elif tool == 'SMSNet':
                    self.process_smsnet(input_file, mgf_file, mab_output_path)
                    
            except Exception as e:
                print(f"Error processing {tool} for {mab}: {e}")
                continue


def main():
    """Main function to run ALPS Fusion assembly."""
    parser = argparse.ArgumentParser(description='ALPS Fusion Assembly Script')
    
    # Load config first to get default values
    config = get_config_loader()
    default_params = config.default_parameters
    default_paths = config.default_paths
    
    parser.add_argument('--tool', type=str, required=True, choices=list(config.tool_names),
                       help='Tool to process')
    parser.add_argument('--input_path', type=str, required=True,
                       help='Base input path containing de novo results')
    parser.add_argument('--output_path', type=str, required=True,
                       help='Base output path for ALPS assembly results')
    parser.add_argument('--mgf_path', type=str,
                       help='Base path to MGF files (required for some tools)')
    parser.add_argument('--confidence_threshold_file', type=str,
                       default=default_paths.get('confidence_threshold_file'),
                       help='Path to CSV file containing confidence thresholds')
    parser.add_argument('--alps_jar_path', type=str, 
                       default=default_paths.get('alps_jar_path'),
                       help='Path to ALPS.jar file')
    parser.add_argument('--names_mapping_file', type=str,
                       help='Path to JSON file containing names mapping')
    parser.add_argument('--config_path', type=str,
                       help='Path to configuration YAML file')
    parser.add_argument('--quality_cutoff', type=int, default=default_params.get('quality_cutoff', 50),
                       help='Quality cutoff threshold')
    parser.add_argument('--kmer', type=int, default=default_params.get('kmer', 7),
                       help='K-mer size for ALPS assembly')
    parser.add_argument('--contigs_alps', type=int, default=default_params.get('contigs_alps', 20),
                       help='Number of contigs for ALPS assembly')

    args = parser.parse_args()

    # Load names mapping if provided
    names_mapping = None
    if args.names_mapping_file and os.path.exists(args.names_mapping_file):
        with open(args.names_mapping_file, 'r') as f:
            names_mapping = json.load(f)

    # Initialize ALPS Fusion processor with config
    alps_fusion = ALPSFusion(
        confidence_threshold_file=args.confidence_threshold_file,
        alps_jar_path=args.alps_jar_path,
        config_path=args.config_path
    )
    
    # Override parameters if provided
    alps_fusion.quality_cutoff = args.quality_cutoff
    alps_fusion.kmer = args.kmer
    alps_fusion.contigs_alps = args.contigs_alps

    # Create output directories
    os.makedirs(args.output_path, exist_ok=True)

    # Process the specified tool
    try:
        alps_fusion.process_tool(args.tool, args.input_path, args.output_path, 
                               args.mgf_path, names_mapping)
        print(f"Successfully processed {args.tool}")
    except Exception as e:
        print(f"Error processing {args.tool}: {e}")
        return 1

    return 0


if __name__ == '__main__':
    exit(main())
